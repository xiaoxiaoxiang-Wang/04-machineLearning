# 01-销量预测

数据：物件的类别 物件的ID(独立，与其他无关) 物件的店铺ID 物件的价格 物件的销售日期 物件销售日期的区间块 物件的名字 物件的店名 物件的销售日期 1.id类特征 类别/物件ID/店铺ID 其他特征 价格 日期
2.画图查看各类特征和销量的关系 3.回归问题 4.每个物件训练一个模型，模型根据每月的销量做回归 5.去除异常点

# 数据处理

数据清洗（缺失值以及异常值的处理） 特征工程（基于对现有数据特征的理解构造的新特征，以挖掘数据的更多特点） 同组识别（找出具有明显同组效应且违背整体规律的数据，对其数据进行修正） 筛选子集（对数据进行降维，选择子集）

# one hot encoding

# label encoder

时间序列模型 交叉验证

#

时间序列，未来的值依赖于当前的值 例如杨辉三角，斐波那契数列

# pandas技巧

# 这一列等于下一列

v[::34] = v[1::34]

# left join指定列

sales_train = pd.merge(sales_train, item.iloc[:, [1, 2]], on=['item_id'], how='left')

# group

groups = sales_train.groupby(['shop_id', 'item_id'])
for name, group in groups:

# Decision Tree

决策树：一颗树，不支持分类，CART支持回归  
分裂特征选择：1.ID3 分裂后熵越小，即信息增益越大; 2.C4.5 信息增益比越大  
贪婪算法，各个决策树可能具有很高的相关性  
如何剪枝：预剪枝，及早的停止树增长；后剪枝，验证集准确率上升就继续剪  
多个特征如何处理：  
对某个特征分裂后，对分裂后的各个节点重复相同的操作  
ID3、C4.5和CART分类树处理分裂增益的外，还有什么区别：  
ID3每个特征的每个值作为一个分裂节点，是多叉树 CART分类树是二叉树

# Bagging

多颗决策树

# Random Forest

# Boosting

# Gradient Boosting Decision Tree

GB和CART的区别:
CART一个特征使用后不再使用，并且只有一颗树。 GBDT有多颗树，每棵树依赖于上一棵树的残差，每棵树都使用完整的数据集

# xgboost
